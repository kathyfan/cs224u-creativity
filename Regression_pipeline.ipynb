{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regression_pipeline.ipynb","provenance":[{"file_id":"1TbT1oPbbeEW7w-1XoUmceB67Z6hgJv9L","timestamp":1621569604758}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fa80c969c2c14b478caffc7d37384384":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b60402a9beae452eb791e6d3caf644ea","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c084b8dc32d442fe9310792cd36e657c","IPY_MODEL_7f14314f8e9947a4bc9f83737f137386"]}},"b60402a9beae452eb791e6d3caf644ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c084b8dc32d442fe9310792cd36e657c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c8314794652f4c09922340116c972962","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7927b9590f3b435da0347bce52ce60dc"}},"7f14314f8e9947a4bc9f83737f137386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9254fe5fc823456bb534029578e4afb1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:02&lt;00:00, 94.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5290ba323ad94ad3b3a02d291fed4cb0"}},"c8314794652f4c09922340116c972962":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7927b9590f3b435da0347bce52ce60dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9254fe5fc823456bb534029578e4afb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5290ba323ad94ad3b3a02d291fed4cb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2200957fd62b45999a0bf09d10aafd09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2fd29741371347b29d3ab79702293f89","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ca00d8df97514714ba60deb51512397f","IPY_MODEL_be5d412ffb7b439f977f29c84fef6974"]}},"2fd29741371347b29d3ab79702293f89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca00d8df97514714ba60deb51512397f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cae5484150364375b7e97bd83366b9f9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acd20cabcaca47898ce9e056f81dab57"}},"be5d412ffb7b439f977f29c84fef6974":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d474015aada485883408a7c89d6d190","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:01&lt;00:00, 27.6B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1397386380fe4080ad53a54958c2fbe6"}},"cae5484150364375b7e97bd83366b9f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acd20cabcaca47898ce9e056f81dab57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d474015aada485883408a7c89d6d190":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1397386380fe4080ad53a54958c2fbe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57d1101e366c43e488111e81e56639f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c60890f71d0241f698caf3304e727668","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d0a6d051ee204c33a851ed98dc6cbf33","IPY_MODEL_746f4e383e0047b28e64d9d93fffe0aa"]}},"c60890f71d0241f698caf3304e727668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0a6d051ee204c33a851ed98dc6cbf33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5d4d62208b0e45b5a063e2d85ab07ce1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b21f2efe553e4b388d8647e06e8288f2"}},"746f4e383e0047b28e64d9d93fffe0aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_15f6d4fd47d0447597adc90e439d2483","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 1.05MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7dbec6e19ec470c9f7289056fc4bfb1"}},"5d4d62208b0e45b5a063e2d85ab07ce1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b21f2efe553e4b388d8647e06e8288f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15f6d4fd47d0447597adc90e439d2483":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7dbec6e19ec470c9f7289056fc4bfb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0861ec9ac15401783bfd9e92487fe43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a52fa27484f34ebdb0abc12c73bf07df","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f785c79f13a48099bbb1477df8aa16d","IPY_MODEL_0feedfdfac074b0fb7a7950a8a65fe6e"]}},"a52fa27484f34ebdb0abc12c73bf07df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f785c79f13a48099bbb1477df8aa16d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_35389ca9c4134cd2bd3db516a30f805b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":442,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_082ca58e4f2f42d7af0230ed3b5c40e4"}},"0feedfdfac074b0fb7a7950a8a65fe6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7ce597d0d0741f5aca0711118f7c9f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442/442 [00:00&lt;00:00, 1.22kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64b90e94382b477cad9365457ce1476f"}},"35389ca9c4134cd2bd3db516a30f805b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"082ca58e4f2f42d7af0230ed3b5c40e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7ce597d0d0741f5aca0711118f7c9f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64b90e94382b477cad9365457ce1476f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e67df8d4c044ab0b4e11d19b7183d30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d2eca679c7ac4bb7acb8a8950a83cbff","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8d6916f93ffc41cca2bf8be42251ab5f","IPY_MODEL_2f9ea867a0594f9f98d88b79106f03a5"]}},"d2eca679c7ac4bb7acb8a8950a83cbff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d6916f93ffc41cca2bf8be42251ab5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3548e016675142abb7dc0200635130b8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8774db4d488540d5a640356bceefdb04"}},"2f9ea867a0594f9f98d88b79106f03a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0b8894c06e5406098b1b70403041316","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 268M/268M [00:08&lt;00:00, 31.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_382c65ed728d4b2ca46a7b83468c6d73"}},"3548e016675142abb7dc0200635130b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8774db4d488540d5a640356bceefdb04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0b8894c06e5406098b1b70403041316":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"382c65ed728d4b2ca46a7b83468c6d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"p270iyuaIsPb"},"source":["This notebook is written based on [this reference implementation](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb).\n","\n","Other refs for model:\n","* https://stackoverflow.com/questions/65205582/how-can-i-add-a-bi-lstm-layer-on-top-of-bert-model\n","* https://discuss.pytorch.org/t/how-to-connect-hook-two-or-even-more-models-together/21033\n","* https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","* https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n","\n","Other refs for torchtext:\n","* https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-i-5da6f1c89d84\n","* https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-ii-f146c8b9a496\n","* http://anie.me/On-Torchtext/"]},{"cell_type":"markdown","metadata":{"id":"FRXm2FfxzC9A"},"source":["# Imports and setup"]},{"cell_type":"code","metadata":{"id":"Kd2O789-y-Hh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621625566700,"user_tz":420,"elapsed":21919,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"ab5d6f6f-eee0-4c5d-f6ee-021332f00e85"},"source":["# Mount Google Drive.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPBhuqfq2PcN","executionInfo":{"status":"ok","timestamp":1621625573035,"user_tz":420,"elapsed":6340,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"46dcac9f-31a0-4f30-dbdf-8ca6255022cf"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 14.2MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 52.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 49.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QtVQ8yVAzMTS","executionInfo":{"status":"ok","timestamp":1621625578255,"user_tz":420,"elapsed":5222,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import random\n","random.seed(1)\n","import re\n","\n","# Data processing.\n","import torch\n","from torchtext.legacy import data \n","\n","# Model.\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import DistilBertModel, DistilBertTokenizer\n","\n","# Training.\n","from sklearn.model_selection import KFold\n","\n","# Visualization.\n","import matplotlib.pyplot as plt\n","\n","# Set working directory.\n","os.chdir('/content/gdrive/My Drive/personal/CS224U/project')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ql2Dve4xza-Z"},"source":["# Load a pre-trained BERT model"]},{"cell_type":"code","metadata":{"id":"gLPcwP45zoL5","colab":{"base_uri":"https://localhost:8080/","height":333,"referenced_widgets":["fa80c969c2c14b478caffc7d37384384","b60402a9beae452eb791e6d3caf644ea","c084b8dc32d442fe9310792cd36e657c","7f14314f8e9947a4bc9f83737f137386","c8314794652f4c09922340116c972962","7927b9590f3b435da0347bce52ce60dc","9254fe5fc823456bb534029578e4afb1","5290ba323ad94ad3b3a02d291fed4cb0","2200957fd62b45999a0bf09d10aafd09","2fd29741371347b29d3ab79702293f89","ca00d8df97514714ba60deb51512397f","be5d412ffb7b439f977f29c84fef6974","cae5484150364375b7e97bd83366b9f9","acd20cabcaca47898ce9e056f81dab57","8d474015aada485883408a7c89d6d190","1397386380fe4080ad53a54958c2fbe6","57d1101e366c43e488111e81e56639f8","c60890f71d0241f698caf3304e727668","d0a6d051ee204c33a851ed98dc6cbf33","746f4e383e0047b28e64d9d93fffe0aa","5d4d62208b0e45b5a063e2d85ab07ce1","b21f2efe553e4b388d8647e06e8288f2","15f6d4fd47d0447597adc90e439d2483","d7dbec6e19ec470c9f7289056fc4bfb1","b0861ec9ac15401783bfd9e92487fe43","a52fa27484f34ebdb0abc12c73bf07df","5f785c79f13a48099bbb1477df8aa16d","0feedfdfac074b0fb7a7950a8a65fe6e","35389ca9c4134cd2bd3db516a30f805b","082ca58e4f2f42d7af0230ed3b5c40e4","b7ce597d0d0741f5aca0711118f7c9f0","64b90e94382b477cad9365457ce1476f","6e67df8d4c044ab0b4e11d19b7183d30","d2eca679c7ac4bb7acb8a8950a83cbff","8d6916f93ffc41cca2bf8be42251ab5f","2f9ea867a0594f9f98d88b79106f03a5","3548e016675142abb7dc0200635130b8","8774db4d488540d5a640356bceefdb04","f0b8894c06e5406098b1b70403041316","382c65ed728d4b2ca46a7b83468c6d73"]},"executionInfo":{"status":"ok","timestamp":1621625589539,"user_tz":420,"elapsed":11286,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"c4c84928-8b41-434f-c81c-e5c5c4613e17"},"source":["WEIGHTS_NAME = 'distilbert-base-uncased'\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(WEIGHTS_NAME)\n","bert = DistilBertModel.from_pretrained(WEIGHTS_NAME)"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa80c969c2c14b478caffc7d37384384","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2200957fd62b45999a0bf09d10aafd09","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57d1101e366c43e488111e81e56639f8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0861ec9ac15401783bfd9e92487fe43","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e67df8d4c044ab0b4e11d19b7183d30","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"PL4p_28SzGCv"},"source":["# Read the data"]},{"cell_type":"code","metadata":{"id":"j5vqzjM_WJ8l","executionInfo":{"status":"ok","timestamp":1621625589540,"user_tz":420,"elapsed":14,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# A utility function for reading data\n","# Takes the number of the study/sample and the label we want to extract (e.g., \"Novelty_Combined\")\n","# Return the a df with a column named 'text' and a column named 'label'\n","# Can also choose to shuffle\n","def get_data(study, metric, shuffle = True):\n","\n","  sheet_df = pd.read_excel(\"Idea Ratings_Berg_2019_OBHDP.xlsx\", sheet_name=study-1) \n","  sheet_df.dropna(inplace=True)\n","  data_df = sheet_df[['Final_Idea', metric]].rename(columns={'Final_Idea': 'text', metric: 'label'})\n","\n","  if shuffle:\n","    data_df = data_df.sample(frac=1)\n","  return data_df\n","\n","# Take a list with the numbers of studies\n","# Extract multiple datasets with get_data and concatenate them\n","def get_multiple_datasets(study_list, metric, shuffle = True):\n","  dfs = [get_data(study, metric, shuffle) for study in study_list]\n","  return pd.concat(dfs)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HwNKmWDey-q9","executionInfo":{"status":"ok","timestamp":1621625592336,"user_tz":420,"elapsed":2809,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["data_df = get_multiple_datasets([0,1,2], 'Creativity_Combined', shuffle=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvWVLrupUEnt","executionInfo":{"status":"ok","timestamp":1621625593325,"user_tz":420,"elapsed":1002,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# For prototype purposes:\n","# split into train, test sets. (Train set will be further split into \n","# train+validation sets, via k-fold CV.)\n","train_df = data_df[:1000]\n","test_df = data_df[1000:] # roughly 190 test examples set aside\n","\n","# write them to CSV files\n","train_df.to_csv('ktrain.csv', index=False, header=False)\n","test_df.to_csv('ktest.csv', index=False, header=False)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXVH4t-UC_wD"},"source":["## Preprocessing and transform into torchtext Dataset format.\n","\n","From what I understand, some preprocessing is done when data.Field() is applied."]},{"cell_type":"code","metadata":{"id":"ifqSE8yj76Vb","executionInfo":{"status":"ok","timestamp":1621625596002,"user_tz":420,"elapsed":2679,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["INIT_TOKEN_IDX = tokenizer.cls_token_id\n","EOS_TOKEN_IDX = tokenizer.sep_token_id\n","PAD_TOKEN_IDX = tokenizer.pad_token_id\n","UNK_TOKEN_IDX = tokenizer.unk_token_id\n","\n","# BERT input can be at most 512 words\n","MAX_INPUT_LENGTH = tokenizer.max_model_input_sizes[WEIGHTS_NAME]\n","\n","# Apply tokenization and some preprocessing steps to the input sentence.\n","# Namely, this trims examples down to MAX_INPUT_LENGTH. (There is a -2 \n","# since the [CLS] and [SEP] tokens will be added)\n","def tokenize_and_cut(sentence):\n","  sentence = sentence.replace('/', '') # remove slashes\n","  tokens = tokenizer.tokenize(sentence) \n","  tokens = tokens[:MAX_INPUT_LENGTH-2]\n","  return tokens\n","\n","# text_fields defines preprocessing and handling of the text of an example.\n","text_fields = data.Field(batch_first = True,\n","                  use_vocab = False,\n","                  tokenize = tokenize_and_cut,\n","                  preprocessing = tokenizer.convert_tokens_to_ids,\n","                  init_token = INIT_TOKEN_IDX, # add [CLS] token\n","                  eos_token = EOS_TOKEN_IDX, # add [SEP] token\n","                  pad_token = PAD_TOKEN_IDX,\n","                  unk_token = UNK_TOKEN_IDX)\n","\n","# label_fields defines how to handle the label of an example.\n","# for regression, we do not need to build a vocabulary.\n","label_fields = data.LabelField(sequential=False, use_vocab=False, dtype = torch.float)\n","all_fields = [('text', text_fields), ('label', label_fields)] # must match order of cols in csv\n","\n","train_dataset, test_dataset = data.TabularDataset.splits(\n","  path='', # path='' because the csvs are in the same directory\n","  train='ktrain.csv', test='ktest.csv', format='csv',\n","  fields=all_fields  \n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dNREAkRrITo","executionInfo":{"status":"ok","timestamp":1621625596006,"user_tz":420,"elapsed":16,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# # Just inspect what the tokenizer is doing\n","# # // and escape characters \\ are kept. We may want to remove them\n","# print(data_df['text'][1])\n","# print(tokenize_and_cut(data_df['text'][1]))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfxEmIj65PFa","executionInfo":{"status":"ok","timestamp":1621625596006,"user_tz":420,"elapsed":15,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# Transform train_dataset into an np array representation.\n","# This will be used for generating the K folds.\n","train_exs_arr = np.array(train_dataset.examples)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GXHfsEVkJ8k6"},"source":["# Define the BERT-RNN model"]},{"cell_type":"code","metadata":{"id":"AHsN05EpJ-dz","executionInfo":{"status":"ok","timestamp":1621625596007,"user_tz":420,"elapsed":15,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["class BERTRNN(nn.Module):\n","  def __init__(self,\n","               bert,\n","               hidden_dim,\n","               output_dim,\n","               n_layers,\n","               bidirectional,\n","               dropout):\n","    super().__init__()\n","    self.bert = bert\n","    # Modify this if we want to concatenate something onto BERT embedding\n","    # Note: 'dim' is equivalent of 'hidden_size' for BERT model\n","    embedding_dim = bert.config.to_dict()['dim']\n","\n","    # TODO: change to lstm cells.\n","    # self.rnn = nn.GRU(embedding_dim,\n","    #                   hidden_dim,\n","    #                   num_layers = n_layers,\n","    #                   bidirectional = bidirectional,\n","    #                   batch_first = True,\n","    #                   dropout = 0 if n_layers < 2 else dropout)\n","    \n","    # TODO: need to modify this if we want to set bidirectional=True\n","    self.out = nn.Linear(hidden_dim, output_dim)\n","    self.dropout = nn.Dropout(dropout)\n","    # TODO: we probably need some regression output layer instead.\n","\n","  def forward(self, text):\n","    # forward pass of bert; then take the output of CLS token\n","    embedded = self.bert(text)[0]\n","\n","    _, hidden = self.rnn(embedded)\n","\n","    # TODO: need to modify this if bidirectional=True\n","    # for prototype purposes, assume we won't use bidirectional\n","    hidden = self.dropout(hidden[-1,:,:])\n","    output = self.out(hidden)\n","    return output\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkXji1DAfwnd","executionInfo":{"status":"ok","timestamp":1621625596007,"user_tz":420,"elapsed":15,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["import torch\n","torch.cuda.empty_cache()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Atbwnil81dS","executionInfo":{"status":"ok","timestamp":1621625596008,"user_tz":420,"elapsed":15,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# Instantiate the model\n","HIDDEN_DIM = 64\n","OUTPUT_DIM = 1\n","N_LAYERS = 1\n","BIDIRECTIONAL = False\n","DROPOUT = 0.25\n","\n","model = BERTRNN(bert,\n","                HIDDEN_DIM,\n","                OUTPUT_DIM,\n","                N_LAYERS,\n","                BIDIRECTIONAL,\n","                DROPOUT)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wb9qlt-_0xlO"},"source":["# Training pipeline begins here\n"]},{"cell_type":"markdown","metadata":{"id":"aSm060wNE-NF"},"source":["## Define training parameters"]},{"cell_type":"code","metadata":{"id":"Ht9cEYK_TeGB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621625602743,"user_tz":420,"elapsed":6750,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"01d6745b-e8d8-46b7-efd2-569654d1a558"},"source":["BATCH_SIZE = 4\n","N_EPOCHS = 2 # TODO we can increase this\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.MSELoss(size_average=False)\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Puhyx2QX_Ax4","executionInfo":{"status":"ok","timestamp":1621625602743,"user_tz":420,"elapsed":19,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# model.train() # Uncomment to view structure of model."],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8Dx5wUUFP2h"},"source":["## Define helper functions"]},{"cell_type":"code","metadata":{"id":"8GqqMgkoSXAW","executionInfo":{"status":"ok","timestamp":1621625602744,"user_tz":420,"elapsed":18,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["def train(model, iterator, optimizer, criterion):\n","  epoch_loss = 0\n","  epoch_corr = 0\n","  \n","  model.train()\n","\n","  for batch in iterator:\n","    optimizer.zero_grad()\n","    predictions = model(batch.text).squeeze(1)\n","    loss = criterion(predictions, batch.label)\n","    # need to use detach() since `predictions` requires gradient\n","    # alternative: scipy.stats.pearsonr? (might be more memory efficient,\n","    # but not sure which one is more efficient to compute)\n","    corr = np.corrcoef(batch.label.cpu().data.numpy(), predictions.detach().cpu().data.numpy())\n","    loss.backward()\n","    optimizer.step()\n","\n","    epoch_loss += loss.item()\n","    # corr is a (2,2) matrix, so we just get the top right element.\n","    # If the correlation is a nan value, replace with 0, which means\n","    # no correlation.\n","    corr_value = corr[0][1].item()\n","    if np.isnan(corr[0][1]):\n","      corr_value = 0\n","\n","    epoch_corr += corr_value\n","\n","  return epoch_loss / len(iterator), epoch_corr / len(iterator)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xE6LEiJTMAc","executionInfo":{"status":"ok","timestamp":1621625602744,"user_tz":420,"elapsed":18,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["def evaluate(model, iterator, criterion):\n","  epoch_loss = 0\n","  epoch_corr = 0\n","\n","  model.eval()\n","\n","  # i = 0\n","  with torch.no_grad():\n","    for batch in iterator:\n","      # print(i)\n","      # i += 1\n","      predictions = model(batch.text).squeeze(1)\n","      # print(predictions) # uncomment to see how the predictions look compared to labels\n","      # print(batch.label)\n","      loss = criterion(predictions, batch.label)\n","      corr = np.corrcoef(batch.label.cpu().data, predictions.cpu().data)\n","      epoch_loss += loss.item()\n","\n","      # If the correlation is a nan value, replace with 0, which means\n","      # no correlation.\n","      corr_value = corr[0][1].item()\n","      if np.isnan(corr[0][1]):\n","        corr_value = 0\n","\n","      epoch_corr += corr_value\n","\n","  return epoch_loss / len(iterator), epoch_corr / len(iterator)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"87B9_LRZ_Jtk","executionInfo":{"status":"ok","timestamp":1621625602745,"user_tz":420,"elapsed":18,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}}},"source":["# Given train and validation datasets, returns 2 iterators.\n","def get_iterators(train_data, valid_data):\n","  return data.BucketIterator.splits(\n","    (train_data, valid_data),\n","    batch_size = BATCH_SIZE,\n","    device = device,\n","    # Below are needed to overcome error when calling evaluate():\n","    # TypeError: '<' not supported between instances of 'Example' and 'Example'\n","    sort_key = lambda x: len(x.text),\n","    sort_within_batch = False,\n","  )"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pKN3vFd0FSre"},"source":["## The cell where it actually trains!"]},{"cell_type":"code","metadata":{"id":"2rJKFKqxSXLE","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"error","timestamp":1621625602985,"user_tz":420,"elapsed":258,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"5c30be6e-ce82-40ef-c9e5-8e4bd2df5f82"},"source":["# The main training loop\n","# TODO: add some sort of weights-saving, either periodically or at the end\n","# This way we can save our trained model and use it easily for downstream\n","# analysis without having to re-train.\n","# TODO: add some sort of timing info / progress bar.\n","def launch_experiment(train_data_df):\n","  best_valid_loss = float('inf') \n","  \n","  kf = KFold(n_splits=5)\n","  for train_index, valid_index in kf.split(train_data_df):\n","    train_data = data.Dataset(train_exs_arr[train_index], all_fields)\n","    valid_data = data.Dataset(train_exs_arr[valid_index], all_fields)\n","\n","    train_iterator, valid_iterator = get_iterators(train_data, valid_data)\n","\n","    \n","\n","    for epoch in range(N_EPOCHS):\n","      train_loss, train_corr = train(model, train_iterator, optimizer, criterion)\n","      valid_loss, valid_corr = evaluate(model, valid_iterator, criterion)\n","\n","      if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","\n","      print(f'\\tTrain Loss: {train_loss:.3f} | Train Corr: {train_corr:.2f}')\n","      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Corr: {valid_corr:.2f}')\n","  \n","  return best_valid_loss \n","\n","launch_experiment(train_exs_arr)\n","#print(best_valid_loss)"],"execution_count":19,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-687e636e6e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mlaunch_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_exs_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#print(best_valid_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-687e636e6e08>\u001b[0m in \u001b[0;36mlaunch_experiment\u001b[0;34m(train_data_df)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-23b3d45e37fa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# need to use detach() since `predictions` requires gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-618d2439f375>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# TODO: need to modify this if bidirectional=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'BERTRNN' object has no attribute 'rnn'"]}]},{"cell_type":"markdown","metadata":{"id":"NIXP6rB_FY8K"},"source":["# Test the trained model on held-out dataset."]},{"cell_type":"code","metadata":{"id":"-1w-zVceFsx3"},"source":["# Get a test iterator\n","test_iterator = data.BucketIterator(\n","  test_dataset,\n","  batch_size = BATCH_SIZE,\n","  device = device,\n","  # Below are needed to overcome error when calling evaluate():\n","  # TypeError: '<' not supported between instances of 'Example' and 'Example'\n","  sort_key = lambda x: len(x.text),\n","  sort_within_batch = False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgAhdm2rTGrP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621580211381,"user_tz":420,"elapsed":18,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"4e305da0-ec5d-4406-9fb9-7f634df6c507"},"source":["test_loss, test_corr = evaluate(model, test_iterator, criterion)\n","print(test_loss)\n","print(test_corr)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n","  c /= stddev[:, None]\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n","  c /= stddev[None, :]\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2551: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  c = cov(x, y, rowvar)\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2480: RuntimeWarning: divide by zero encountered in true_divide\n","  c *= np.true_divide(1, fact)\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2480: RuntimeWarning: invalid value encountered in multiply\n","  c *= np.true_divide(1, fact)\n"],"name":"stderr"},{"output_type":"stream","text":["2.312805041721141\n","-0.07726163023834338\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l5g0MO_uYqn7"},"source":["# Misc other stuff"]},{"cell_type":"code","metadata":{"id":"5ynFXY3YUusc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621580211382,"user_tz":420,"elapsed":16,"user":{"displayName":"Xubo Cao","photoUrl":"","userId":"10438589586656072815"}},"outputId":"483cd2f5-7f60-467a-bfe0-7841f43d07a9"},"source":["# When predictions are all identical, we will get a nan value (https://www.kaggle.com/general/186524)\n","k_pred = np.array([1.5818, 1.5818, 1.5818, 1.5818, 1.5818, 1.5818, 1.5818, 1.5818, 1.5818,\n","        1.5818, 1.5818, 1.5818, 1.5818, 1.5818, 1.5818, 1.5818])\n","k_label = np.array([3.0500, 4.5750, 3.8500, 2.2750, 4.1000, 3.9000, 3.3750, 2.9750, 4.0500,\n","        4.5000, 3.8500, 3.6250, 4.0000, 5.4750, 3.2250, 3.5500])\n","print(np.corrcoef(k_label, k_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 1. nan]\n"," [nan nan]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n","  c /= stddev[:, None]\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n","  c /= stddev[None, :]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hKAyPvJ49eBa"},"source":["# I use this chunk to collect code from happy transformer that may be relevant to our study\n","    def _get_training_args(args, output_path):\n","        \"\"\"\n","        :param args: a dictionary of arguments for training\n","        :param output_path: A string to a temporary directory\n","        :return: A TrainingArguments object\n","        \"\"\"\n","        return TrainingArguments(\n","            output_dir=output_path,\n","            learning_rate=args[\"learning_rate\"],\n","            weight_decay=args[\"weight_decay\"],\n","            adam_beta1=args[\"adam_beta1\"],\n","            adam_beta2=args[\"adam_beta2\"],\n","            adam_epsilon=args[\"adam_epsilon\"],\n","            max_grad_norm=args[\"max_grad_norm\"],\n","            num_train_epochs=args[\"num_train_epochs\"],\n","\n","        )\n","\n","    def _run_train(self, dataset, args):\n","    \"\"\"\n","\n","    :param dataset: a child of torch.utils.data.Dataset\n","    :param args: a dictionary that contains settings\n","    :return: None\n","    \"\"\"\n","    with tempfile.TemporaryDirectory() as tmp_dir_name:\n","        training_args = self._get_training_args(args, tmp_dir_name)\n","        trainer = Trainer( #This trainer class comes from hugging face\n","            model=self.model,\n","            args=training_args,\n","            train_dataset=dataset,\n","        )\n","        trainer.train()\n","\n","# The actual class used in my study\n","class DistilBertForSequenceClassification(DistilBertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.config = config\n","\n","        self.distilbert = DistilBertModel(config)\n","        self.pre_classifier = nn.Linear(config.dim, config.dim)\n","        self.classifier = nn.Linear(config.dim, config.num_labels)\n","        self.dropout = nn.Dropout(config.seq_classif_dropout)\n","\n","        self.init_weights()\n","\n","[DOCS]    @add_start_docstrings_to_model_forward(DISTILBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n","    @add_code_sample_docstrings(\n","        tokenizer_class=_TOKENIZER_FOR_DOC,\n","        checkpoint=_CHECKPOINT_FOR_DOC,\n","        output_type=SequenceClassifierOutput,\n","        config_class=_CONFIG_FOR_DOC,\n","    )\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n","            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n","            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        distilbert_output = self.distilbert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n","        pooled_output = hidden_state[:, 0]  # (bs, dim)\n","        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n","        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n","        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n","        logits = self.classifier(pooled_output)  # (bs, num_labels)\n","\n","        loss = None\n","        if labels is not None:\n","            if self.config.problem_type is None:\n","                if self.num_labels == 1:\n","                    self.config.problem_type = \"regression\"\n","                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n","                    self.config.problem_type = \"single_label_classification\"\n","                else:\n","                    self.config.problem_type = \"multi_label_classification\"\n","\n","            if self.config.problem_type == \"regression\":\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels)\n","            elif self.config.problem_type == \"single_label_classification\":\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            elif self.config.problem_type == \"multi_label_classification\":\n","                loss_fct = BCEWithLogitsLoss()\n","                loss = loss_fct(logits, labels)\n","\n","        if not return_dict:\n","            output = (logits,) + distilbert_output[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=distilbert_output.hidden_states,\n","            attentions=distilbert_output.attentions,\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IebHhmzl_anV"},"source":["Link to the trainer class: https://huggingface.co/transformers/main_classes/trainer.html\n","\n","\n","\n","Default training arguments: https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments\n","\n","Batch size per device: 8\n","\n","Epoch: 3\n","\n","\n","\n","This should be the model I used to generate my initial results: https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n","\"DistilBert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE tasks.\""]}]}